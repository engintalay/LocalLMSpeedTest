# LLM Benchmark Tool

Local LLM performans testi iÃ§in interaktif Python aracÄ±. Ollama, LM Studio ve llama.cpp gibi yerel LLM backend'lerini test eder.

## Ã–zellikler

- **Ã‡oklu Backend DesteÄŸi**: Ollama, LM Studio, llama.cpp
- **HazÄ±r Prompt Koleksiyonu**: KÄ±sa, orta, uzun ve ekstra uzun promptlar
- **DetaylÄ± Metrikler**: Token/saniye, yanÄ±t sÃ¼resi, toplam token sayÄ±sÄ±
- **Ã‡oklu Test Ä°terasyonu**: Ortalama performans hesaplama
- **Toplu Test Modu**: TÃ¼m modelleri tek seferde test et
- **Performans Ã–zeti**: SonuÃ§larÄ± hÄ±zdan yavaÅŸa sÄ±ralÄ± tablo
- **Interaktif MenÃ¼**: Kolay kullanÄ±m iÃ§in klavye navigasyonu
- **SonuÃ§ Kaydetme**: Test sonuÃ§larÄ±nÄ± otomatik kaydetme

## Kurulum

```bash
# Depoyu klonlayÄ±n
git clone <repo-url>
cd LocalLMSpeedTest

# Sanal ortam oluÅŸturun
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# veya
venv\Scripts\activate  # Windows

# BaÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kleyin
pip install requests readchar
```

## KullanÄ±m

```bash
python llm-benchmark.py
```

### MenÃ¼ Navigasyonu

- **â†‘/â†“**: SeÃ§enekler arasÄ±nda gezinme
- **Enter**: SeÃ§imi onayla
- **q**: Ã‡Ä±kÄ±ÅŸ

### Test AkÄ±ÅŸÄ±

1. Backend seÃ§in (Ollama/LM Studio/llama.cpp)
2. Model seÃ§in veya "Test all models" ile tÃ¼m modelleri seÃ§in
3. Prompt dosyasÄ± seÃ§in veya "Test all prompts" ile tÃ¼m promptlarÄ± seÃ§in
4. Test iterasyon sayÄ±sÄ±nÄ± ayarlayÄ±n
5. Testi Ã§alÄ±ÅŸtÄ±rÄ±n
6. Testler bittiÄŸinde performans Ã¶zeti gÃ¶rÃ¼ntÃ¼lenir (en hÄ±zlÄ±dan yavaÅŸa)

## Prompt Kategorileri

- **short**: 1-12 token (basit sorular)
- **medium**: 100-122 token (kod debug, algoritma)
- **long**: 1200-2300 token (proje analizi, mimari)
- **extra_long**: 17000-44000 token (bÃ¼yÃ¼k kod tabanlarÄ±)

## SonuÃ§lar

Test sonuÃ§larÄ± `results.txt` dosyasÄ±na kaydedilir:

```
Backend: LMSTUDIO
Model: deepseek-coder-v2-lite-16b
Prompt: medium_programming_debug_122t.txt

RESULTS:
  Run 1: 32.28 tok/s
  Run 2: 33.16 tok/s
  Run 3: 33.61 tok/s

AVERAGE: 33.02 tok/s
```

### Performans Ã–zeti

Testler tamamlandÄ±ÄŸÄ±nda, tÃ¼m sonuÃ§lar hÄ±zdan yavaÅŸa sÄ±ralÄ± olarak gÃ¶sterilir:

```
ğŸ“Š PERFORMANCE SUMMARY (Fastest to Slowest)
================================================================================

1. model-name-1                          | prompt-file.txt                | 45.23 tok/s
2. model-name-2                          | prompt-file.txt                | 33.02 tok/s
3. model-name-3                          | prompt-file.txt                | 28.15 tok/s

================================================================================
```

## YapÄ±landÄ±rma

Ayarlar `~/.llm-benchmark-config.json` dosyasÄ±nda saklanÄ±r:

```json
{
  "ollama_url": "http://localhost:11434",
  "llamacpp_url": "http://localhost:8080",
  "lmstudio_url": "http://localhost:1234",
  "test_iterations": 3
}
```

## Ek Testler

`machine_tests/` dizininde Ã§eÅŸitli performans testleri bulunmaktadÄ±r (opsiyonel).

## Lisans

MIT
